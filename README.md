# ARIA

<p align="center">
  <strong>AI Realtime Intelligent Audio</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.10+-blue.svg" alt="Python 3.10+">
  <img src="https://img.shields.io/badge/platform-Windows-lightgrey.svg" alt="Windows">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="MIT License">
</p>

**Universal Real-time AI Subtitles for Windows** - Capture and transcribe any audio playing on your system with AI-powered speech recognition.

## âœ¨ Features

- ğŸ¯ **Universal Audio Capture** - Works with any application (games, videos, calls, etc.)
- ğŸš€ **Two Recognition Modes**:
  - **Precise Mode**: Uses Whisper for high-accuracy transcription
  - **Realtime Mode**: Uses Sherpa-ONNX/Vosk for word-by-word streaming
- ğŸŒ **Multi-language Support**: Chinese, English, Japanese, Korean, and more
- ğŸ”„ **Real-time Translation**: Translate transcriptions with Google Cloud or NLLB (local)
- ğŸ¨ **Customizable Overlay**: Draggable subtitle window with adjustable position
- ğŸŒ **Multilingual UI**: English, Traditional Chinese, Simplified Chinese

## ğŸ“¦ Installation

### Prerequisites
- Python 3.10 or higher
- Windows 10/11

### Install from source

```bash
# Clone the repository
git clone https://github.com/sayksii/aria.git
cd aria

# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate

# Install the package
pip install -e .
```

## ğŸš€ Usage

### Launch the GUI

```bash
python -m realtime_subtitles.ui.app
```

Or after installation:
```bash
aria
```

### Quick Start

1. Launch ARIA
2. Select recognition mode (Precise or Realtime)
3. Choose the language you want to recognize
4. Click **Start Subtitles**
5. Drag the subtitle overlay to your preferred position

## âš™ï¸ Configuration

### Recognition Modes

| Mode | Engine | Best For |
|------|--------|----------|
| **Precise** | Whisper | Speeches, videos, pre-recorded content |
| **Realtime** | Sherpa-ONNX / Vosk | Live conversations, streaming |

### Supported Languages

| Language | Precise Mode | Realtime Mode |
|----------|--------------|---------------|
| Chinese (ä¸­æ–‡) | âœ… | âœ… (Sherpa-ONNX) |
| English | âœ… | âœ… (Sherpa-ONNX) |
| Japanese (æ—¥æœ¬èª) | âœ… | âœ… (Vosk) |
| Korean (í•œêµ­ì–´) | âœ… | âŒ |
| + 50 more | âœ… | âŒ |

### Translation

- **Google Cloud**: Fast, accurate, requires internet
- **NLLB Local**: Offline, runs locally using Meta's NLLB model

## ğŸ—ï¸ Project Structure

```
aria/
â”œâ”€â”€ src/realtime_subtitles/
â”‚   â”œâ”€â”€ audio/          # Audio capture (WASAPI loopback)
â”‚   â”œâ”€â”€ recognition/    # Speech recognition engines
â”‚   â”œâ”€â”€ translation/    # Translation engines
â”‚   â”œâ”€â”€ i18n/           # Internationalization
â”‚   â””â”€â”€ ui/             # GUI components
â”œâ”€â”€ models/             # Downloaded AI models (gitignored)
â””â”€â”€ pyproject.toml
```

## ğŸ”§ Development

```bash
# Install with dev dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Lint code
ruff check src/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Faster Whisper](https://github.com/SYSTRAN/faster-whisper) - Fast Whisper inference
- [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx) - Streaming speech recognition
- [Vosk](https://alphacephei.com/vosk/) - Offline speech recognition
- [CustomTkinter](https://github.com/TomSchimansky/CustomTkinter) - Modern UI framework

## ğŸ“§ Contact

- GitHub: [@sayksii](https://github.com/sayksii)
- Email: mark42967151@gmail.com
